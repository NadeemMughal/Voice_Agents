{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNefb0W5Z+C4SuPyQSSp8z1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadeemMughal/Voice_Agents/blob/main/Voice_to_LLM_to_Voice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGEtw1N5jlon",
        "outputId": "8eb5a9d4-eef2-4f6f-c024-c3940c8ed99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUFplz4wjOaZ",
        "outputId": "9d195a29-7406-44c1-f722-a01a329ac1bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting assemblyai\n",
            "  Downloading assemblyai-0.37.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: httpx>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.10.17 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (4.12.2)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (14.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.19.0->assemblyai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai) (2.27.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.19.0->assemblyai) (1.3.1)\n",
            "Downloading assemblyai-0.37.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: assemblyai\n",
            "Successfully installed assemblyai-0.37.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U assemblyai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start by making sure the `assemblyai` package is installed.\n",
        "# If not, you can install it by running the following command:\n",
        "# pip install -U assemblyai\n",
        "#\n",
        "# Note: Some macOS users may need to use `pip3` instead of `pip`.\n",
        "\n",
        "import assemblyai as aai\n",
        "\n",
        "# Replace with your API key\n",
        "aai.settings.api_key = \"78884175e5a3456a9394a33ebf3871a43338122531\"\n",
        "\n",
        "# URL of the file to transcribe\n",
        "FILE_URL = \"/content/drive/MyDrive/Testing_Voice_to_Speech-VOices/Recording.m4a\"\n",
        "\n",
        "# You can also transcribe a local file by passing in a file path\n",
        "# FILE_URL = './path/to/file.mp3'\n",
        "\n",
        "transcriber = aai.Transcriber()\n",
        "transcript = transcriber.transcribe(FILE_URL)\n",
        "\n",
        "if transcript.status == aai.TranscriptStatus.error:\n",
        "    print(transcript.error)\n",
        "else:\n",
        "    print(transcript.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdCrMfQGjiFj",
        "outputId": "19e65270-b5bb-4ae5-d6a0-26ab2af01311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is nadeem, and I am an AI engineer at metaves pro.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_core langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z1Lwa_Sj9Pv",
        "outputId": "4c95faf2-89a7-4401-dbea-5d2d19c4fa2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.35)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (2.10.6)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.26.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.67.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.3.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain_google_genai\n",
            "Successfully installed filetype-1.2.0 langchain_google_genai-2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "SiwYffLXlsIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\", api_key=GEMINI_API_KEY)\n",
        "model.invoke(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnPxIeDilvIp",
        "outputId": "ff97ef6c-4e1b-4e62-d6c0-c07f965cb5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-0a9b2767-e1ed-4d1a-83ac-8570721ca6c0-0', usage_metadata={'input_tokens': 1, 'output_tokens': 10, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import assemblyai as aai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Set up your AssemblyAI API key\n",
        "aai.settings.api_key = \"78884175e5a3456a9394a33ebf3871a43338122531\"  # Replace with your AssemblyAI API key\n",
        "\n",
        "# Set the URL or file path of the audio file to transcribe\n",
        "FILE_URL = \"/content/drive/MyDrive/Testing_Voice_to_Speech-VOices/Recording.m4a\"\n",
        "\n",
        "# Create a transcriber instance and transcribe the audio file\n",
        "transcriber = aai.Transcriber()\n",
        "transcript = transcriber.transcribe(FILE_URL)\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Check the status of the transcription\n",
        "if transcript.status == aai.TranscriptStatus.error:\n",
        "    print(\"Transcription Error:\", transcript.error)\n",
        "else:\n",
        "    # If transcription is successful, get the transcribed text\n",
        "    transcribed_text = transcript.text\n",
        "    print(\"Transcription Output:\", transcribed_text)\n",
        "\n",
        "    # Initialize the Google Generative AI model\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=GEMINI_API_KEY)\n",
        "\n",
        "    # Pass the transcribed text to the LLM and get the response\n",
        "    response = model.invoke(transcribed_text)\n",
        "    print(\"LLM Output:\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1gYfY7_lxQh",
        "outputId": "375d75ac-c453-47dd-ad51-0984fbf86d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Output: Hello, my name is nadeem, and I am an AI engineer at metaves pro.\n",
            "LLM Output: Hello Nadeem, nice to meet you! It's good to connect with another AI engineer, especially one working at Metaves Pro. What kind of AI projects are you currently working on? I'm always interested to hear about the latest developments in the field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import assemblyai as aai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set up your AssemblyAI API key\n",
        "aai.settings.api_key = \"78884175e5a3456a9394a33ebf3871a43338122531\"  # Replace with your AssemblyAI API key\n",
        "\n",
        "# Set the URL or file path of the audio file to transcribe\n",
        "FILE_URL = \"/content/drive/MyDrive/Testing_Voice_to_Speech-VOices/Recording.m4a\"\n",
        "\n",
        "# Create a transcriber instance and transcribe the audio file\n",
        "transcriber = aai.Transcriber()\n",
        "transcript = transcriber.transcribe(FILE_URL)\n",
        "\n",
        "# Get the GEMINI API key from Colab's user data\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Check the status of the transcription\n",
        "if transcript.status == aai.TranscriptStatus.error:\n",
        "    print(\"Transcription Error:\", transcript.error)\n",
        "else:\n",
        "    # If transcription is successful, get the transcribed text\n",
        "    transcribed_text = transcript.text\n",
        "    print(\"Transcription Output:\", transcribed_text)\n",
        "\n",
        "    # Initialize the Google Generative AI model with system prompt\n",
        "\n",
        "    system_prompt = \"\"\"\n",
        "    Role:\n",
        "You are the We Build Trade Assistant, responsible for handling user queries and directing them to Daniel or another relevant person. Your role is to gather the user’s name and message and pass them to the Email custom function for further processing.\n",
        "\n",
        "Skills:\n",
        "Accurately understanding and capturing the user's name and query.\n",
        "Passing the collected details to the Email function for further processing.\n",
        "Keeping interactions professional, polite, and efficient.\n",
        "Objective:\n",
        "Your goal is to:\n",
        "\n",
        "Ask for the user’s name before collecting their query.\n",
        "If the user wants to contact Daniel, inform them that Daniel is a little busy but offer to pass their message to him.\n",
        "Capture the user’s message exactly as they state it without rephrasing or confirming.\n",
        "Pass the name and message to the Email function for further processing.\n",
        "Confirm that the message has been sent successfully without revealing technical details.\n",
        "Wish the user good luck and let them know Daniel will contact them soon, then end the conversation.\n",
        "Rules:\n",
        "Always introduce yourself as the We Build Trade Assistant.\n",
        "Politely ask for the user’s name first.\n",
        "If the user wants to contact Daniel, let them know Daniel is busy and offer to take their message.\n",
        "Capture the user’s name and message exactly as they state it without rephrasing or confirming.\n",
        "Pass the name and message directly to the Email function for further processing.\n",
        "Only inform the user that their message has been sent successfully. Do not show them the message before sending.\n",
        "If the Email function fails, apologize and prompt the user to retry.\n",
        "Do not mention technical details about processing.\n",
        "Keep responses concise, professional, and human-like while ensuring clarity.\n",
        "Do not end the conversation unless the task is completed or the user indicates they are done.\n",
        "Example Flow:\n",
        "User: Hi\n",
        "Assistant: Hello! I’m the We Build Trade Assistant. May I have your name?\n",
        "\n",
        "User: My name is John.\n",
        "Assistant: Thank you, John! Who would you like to contact, and what is your query?\n",
        "\n",
        "User: I want to contact Daniel for growing my business through the best ideas.\n",
        "Assistant: Daniel is a little busy at the moment. If you'd like, I can pass your message to him, and he will get in touch with you soon. What would you like me to pass along?\n",
        "\n",
        "User: I'd like to discuss some new business growth ideas with him.\n",
        "✅ Action: Message is captured as stated by the user, including their name.\n",
        "✅ Processing: Passed directly to the Email function.\n",
        "\n",
        "Assistant: Your message has been successfully sent to Daniel. Good luck with your business, and he will contact you soon. Thank you, and have a great day!\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        system_prompt=system_prompt\n",
        "    )\n",
        "\n",
        "    # Pass the transcribed text to the LLM and get the response\n",
        "    response = model.invoke(transcribed_text)\n",
        "    print(\"LLM Output:\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZcT4ftJrX4H",
        "outputId": "4607f14f-ad15-43dd-a78a-e6cee6b8a322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Output: Hello, my name is nadeem, and I am an AI engineer at metaves pro.\n",
            "LLM Output: Okay, Nadeem. It's nice to meet you virtually! How can I help you today? I understand you are an AI Engineer at Metaves Pro. Let me know what you need from me, whether it's brainstorming, problem-solving, information, or something else. I'm ready to assist in any way I can.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smallest API\n"
      ],
      "metadata": {
        "id": "-qoGXTOwt60n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install smallestai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrFit4NJt6gq",
        "outputId": "3b8f62fe-113b-4d0b-c6e1-abb9ffdad409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting smallestai\n",
            "  Downloading smallestai-2.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from smallestai) (3.11.12)\n",
            "Collecting aiofiles (from smallestai)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from smallestai) (2.32.3)\n",
            "Collecting sacremoses (from smallestai)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pydub (from smallestai)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->smallestai) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->smallestai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->smallestai) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->smallestai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->smallestai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->smallestai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->smallestai) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->smallestai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->smallestai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->smallestai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->smallestai) (2025.1.31)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses->smallestai) (2024.11.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->smallestai) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->smallestai) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses->smallestai) (4.67.1)\n",
            "Downloading smallestai-2.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, sacremoses, aiofiles, smallestai\n",
            "Successfully installed aiofiles-24.1.0 pydub-0.25.1 sacremoses-0.1.1 smallestai-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from smallest import Smallest\n",
        "\n",
        "def main():\n",
        "    client = Smallest(api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9hell.eyJ1c2VySWQiOiI2N2I2YjY1noYzg0N2M2NjMzM2VkNTc1YWYiLCJpYXQiOjE3NDAwMjc1NDN9.RBad1Gq3COhNIQw3kaIkgyFKQsoRKOMgF6MeqPDAyAk\")\n",
        "    client.synthesize(\n",
        "        response.content,\n",
        "        sample_rate=24000,\n",
        "        speed=1.0,\n",
        "        save_as=\"output.wav\"\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "YfMWRZIJspsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM to Text to Speech Realtime"
      ],
      "metadata": {
        "id": "BqWPxokwxXYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5LqMoqoxeT_",
        "outputId": "065210ad-3412-45f2-ef85-310158d368c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key=userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\" # Mock WebSocket server\n",
        "\n",
        "# Async function to stream text generation from LLM\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            yield text\n",
        "\n",
        "# Main function to run the process\n",
        "async def main():\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(\"Explain text to speech like I am five in 5 sentences.\")\n",
        "\n",
        "    # Stream the generated speech throught a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "lbzc4_KVspct",
        "outputId": "2cc5b22e-7bf0-41d1-bd54-38bef6b1e79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-28cf8c1deb1f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# fail fast with short traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key=userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\" # Mock WebSocket server\n",
        "\n",
        "# Async function to stream text generation from LLM\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            yield text\n",
        "\n",
        "# Main function to run the process\n",
        "async def main():\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(\"Explain text to speech like I am five in 5 sentences.\")\n",
        "\n",
        "    # Stream the generated speech throught a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "# Instead of asyncio.run, use the existing event loop\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop() # Get the current event loop\n",
        "    loop.run_until_complete(main()) # Run the 'main' coroutine until it completes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "8AB4ZBFksN0B",
        "outputId": "b4c260e5-f46b-441b-b7ec-5b263873b542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "This event loop is already running",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-86e1e2cfafec>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get the current event loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Run the 'main' coroutine until it completes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m    629\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mnew_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b-_ODI2yEDA",
        "outputId": "d67e6bc1-a8a6-4e05-a800-025d57d13363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio  # Import nest_asyncio\n",
        "\n",
        "from google.colab import userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key = userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\"  # Mock WebSocket server\n",
        "\n",
        "# ... (rest of your code remains the same) ...\n",
        "\n",
        "# Async function to stream text generation from LLM\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            yield text\n",
        "\n",
        "# Main function to run the process\n",
        "async def main():\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(\"Explain text to speech like I am five in 5 sentences.\")\n",
        "\n",
        "    # Stream the generated speech throught a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()  # Apply nest_asyncio patch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj3Ih_TiyN93",
        "outputId": "aba4eeb8-d3a8-4862-fdc7-9ee0b9b9b1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to WebSocket server.\n",
            "Received from server: echo.websocket.event ...\n",
            "Received from server: b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00' ...\n",
            "WebSocket connection closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio  # Import nest_asyncio\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get API keys from Colab's userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key = userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\"  # Mock WebSocket server\n",
        "\n",
        "# Async function to stream text generation from LLM\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            yield text\n",
        "\n",
        "# Async function to process text-to-speech and stream through WebSocket\n",
        "async def process_and_stream(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Stream the generated speech through a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "# Main function to run the real-time input and streaming\n",
        "async def main():\n",
        "    print(\"Real-Time Text to Speech. Type your query and press Enter. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Call the process_and_stream function to handle the user input\n",
        "        await process_and_stream(user_input)\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()  # Apply nest_asyncio patch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR9bbwJnyWCG",
        "outputId": "4a925512-4ce7-4a57-f6f8-19d4fd842b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real-Time Text to Speech. Type your query and press Enter. Type 'exit' to quit.\n",
            "You: hello i am Nadeem.\n",
            "Connected to WebSocket server.\n",
            "Received from server: echo.websocket.event ...\n",
            "WebSocket connection closed.\n",
            "You: exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sounddevice numpy asyncio websockets nest_asyncio groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9W0BERnzFAW",
        "outputId": "1d2c894f-a237-4e7c-8c0a-cc7c4e49062e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.11/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: asyncio in /usr/local/lib/python3.11/dist-packages (3.4.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (14.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice) (1.17.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -qq portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "!pip install sounddevice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLhYUdEbzcgw",
        "outputId": "66b610f3-05e4-416a-8923-ddd9740d1873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.11/dist-packages (0.5.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio  # Import nest_asyncio\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import sounddevice as sd\n",
        "\n",
        "# Get API keys from Colab's userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key = userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\"  # Mock WebSocket server\n",
        "\n",
        "# Audio Configuration\n",
        "SAMPLE_RATE = 16000  # 16 kHz for better TTS quality\n",
        "\n",
        "# Async function to stream text generation from LLM\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            yield text\n",
        "\n",
        "# Function to play audio in real-time\n",
        "def play_audio(audio_chunk):\n",
        "    audio_array = np.frombuffer(audio_chunk, dtype=np.int16)\n",
        "    sd.play(audio_array, SAMPLE_RATE)\n",
        "    sd.wait()  # Wait until the audio is played\n",
        "\n",
        "# Async function to process text-to-speech and stream through WebSocket\n",
        "async def process_and_stream(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Stream the generated speech through a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "            # Play audio in real-time\n",
        "            play_audio(audio_chunk)  # Play the audio chunk locally\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "# Main function to run the real-time input and streaming\n",
        "async def main():\n",
        "    print(\"Real-Time Text to Speech. Type your query and press Enter. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Call the process_and_stream function to handle the user input\n",
        "        await process_and_stream(user_input)\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()  # Apply nest_asyncio patch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fTXuk0s_yuXk",
        "outputId": "6ed47b7e-10d9-489e-a5c7-2d841d17987e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real-Time Text to Speech. Type your query and press Enter. Type 'exit' to quit.\n",
            "You: HI I am Nadeem.\n",
            "Connected to WebSocket server.\n",
            "Received from server: echo.websocket.event ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PortAudioError",
          "evalue": "Error querying device -1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPortAudioError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2debd40fde53>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2debd40fde53>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Call the process_and_stream function to handle the user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0mprocess_and_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Apply nest_asyncio to allow nested event loops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2debd40fde53>\u001b[0m in \u001b[0;36mprocess_and_stream\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Play audio in real-time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mplay_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_chunk\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Play the audio chunk locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WebSocket connection closed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2debd40fde53>\u001b[0m in \u001b[0;36mplay_audio\u001b[0;34m(audio_chunk)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0maudio_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait until the audio is played\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(data, samplerate, mapping, blocking, loop, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     ctx.start_stream(OutputStream, samplerate, ctx.output_channels,\n\u001b[0m\u001b[1;32m    179\u001b[0m                      \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                      \u001b[0mprime_output_buffers_using_stream_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mstart_stream\u001b[0;34m(self, StreamClass, samplerate, channels, dtype, callback, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2624\u001b[0m                      blocking, **kwargs):\n\u001b[1;32m   2625\u001b[0m         \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Stop previous playback/recording\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2626\u001b[0;31m         self.stream = StreamClass(samplerate=samplerate,\n\u001b[0m\u001b[1;32m   2627\u001b[0m                                   \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m                                   \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback)\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \"\"\"\n\u001b[0;32m-> 1515\u001b[0;31m         _StreamBase.__init__(self, kind='output', wrap_callback='array',\n\u001b[0m\u001b[1;32m   1516\u001b[0m                              **_remove_self(locals()))\n\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, kind, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback, userdata, wrap_callback)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_samplesize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 _get_stream_parameters(kind, device, channels, dtype, latency,\n\u001b[0m\u001b[1;32m    829\u001b[0m                                        extra_settings, samplerate)\n\u001b[1;32m    830\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m_get_stream_parameters\u001b[0;34m(kind, device, channels, dtype, latency, extra_settings, samplerate)\u001b[0m\n\u001b[1;32m   2706\u001b[0m         \u001b[0msamplerate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mquery_devices\u001b[0;34m(device, kind)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPa_GetDeviceInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPortAudioError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Error querying device {device}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructVersion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0mname_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPortAudioError\u001b[0m: Error querying device -1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio  # Import nest_asyncio\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import sounddevice as sd\n",
        "\n",
        "# Get API keys from Colab's userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key = userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\"  # Mock WebSocket server\n",
        "\n",
        "# Audio Configuration\n",
        "SAMPLE_RATE = 16000  # 16 kHz for better TTS quality\n",
        "\n",
        "# Async function to stream text generation from LLM\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            yield text\n",
        "\n",
        "# Function to play audio in real-time\n",
        "def play_audio(audio_chunk):\n",
        "    audio_array = np.frombuffer(audio_chunk, dtype=np.int16)\n",
        "    # Explicitly set the output device to the default device (0)\n",
        "    sd.default.device = 0 # sd.default.device[1] for output devices if needed.\n",
        "    # Check available devices:\n",
        "    #print(sd.query_devices())\n",
        "    sd.play(audio_array, SAMPLE_RATE)\n",
        "    sd.wait()  # Wait until the audio is played\n",
        "\n",
        "# Async function to process text-to-speech and stream through WebSocket\n",
        "async def process_and_stream(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Stream the generated speech through a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "            # Play audio in real-time\n",
        "            play_audio(audio_chunk)  # Play the audio chunk locally\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "# Main function to run the real-time input and streaming\n",
        "async def main():\n",
        "    print(\"Real-Time Text to Speech. Type your query and press Enter. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Call the process_and_stream function to handle the user input\n",
        "        await process_and_stream(user_input)\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()  # Apply nest_asyncio patch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "_NkkPcNkzAxy",
        "outputId": "cf0aa835-0dd9-4e56-97d8-0bdce33f9672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real-Time Text to Speech. Type your query and press Enter. Type 'exit' to quit.\n",
            "You: Hi I ma NAdeem\n",
            "Connected to WebSocket server.\n",
            "Received from server: echo.websocket.event ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PortAudioError",
          "evalue": "Error querying device 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPortAudioError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-24bb6f850d52>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-24bb6f850d52>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Call the process_and_stream function to handle the user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0mprocess_and_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Apply nest_asyncio to allow nested event loops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-24bb6f850d52>\u001b[0m in \u001b[0;36mprocess_and_stream\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# Play audio in real-time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mplay_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_chunk\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Play the audio chunk locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WebSocket connection closed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-24bb6f850d52>\u001b[0m in \u001b[0;36mplay_audio\u001b[0;34m(audio_chunk)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Check available devices:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#print(sd.query_devices())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait until the audio is played\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(data, samplerate, mapping, blocking, loop, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     ctx.start_stream(OutputStream, samplerate, ctx.output_channels,\n\u001b[0m\u001b[1;32m    179\u001b[0m                      \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                      \u001b[0mprime_output_buffers_using_stream_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mstart_stream\u001b[0;34m(self, StreamClass, samplerate, channels, dtype, callback, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2624\u001b[0m                      blocking, **kwargs):\n\u001b[1;32m   2625\u001b[0m         \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Stop previous playback/recording\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2626\u001b[0;31m         self.stream = StreamClass(samplerate=samplerate,\n\u001b[0m\u001b[1;32m   2627\u001b[0m                                   \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m                                   \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback)\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \"\"\"\n\u001b[0;32m-> 1515\u001b[0;31m         _StreamBase.__init__(self, kind='output', wrap_callback='array',\n\u001b[0m\u001b[1;32m   1516\u001b[0m                              **_remove_self(locals()))\n\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, kind, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback, userdata, wrap_callback)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_samplesize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 _get_stream_parameters(kind, device, channels, dtype, latency,\n\u001b[0m\u001b[1;32m    829\u001b[0m                                        extra_settings, samplerate)\n\u001b[1;32m    830\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m_get_stream_parameters\u001b[0;34m(kind, device, channels, dtype, latency, extra_settings, samplerate)\u001b[0m\n\u001b[1;32m   2706\u001b[0m         \u001b[0msamplerate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mquery_devices\u001b[0;34m(device, kind)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPa_GetDeviceInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPortAudioError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Error querying device {device}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructVersion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0mname_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPortAudioError\u001b[0m: Error querying device 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the Voice"
      ],
      "metadata": {
        "id": "gRZWqkw-0oMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio  # Import nest_asyncio\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "# import sounddevice as sd  # No longer needed for playing audio\n",
        "import io  # Import io for working with in-memory bytes\n",
        "\n",
        "# Get API keys from Colab's userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key = userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\"  # Mock WebSocket server\n",
        "\n",
        "# Audio Configuration\n",
        "SAMPLE_RATE = 16000  # 16 kHz for better TTS quality\n",
        "\n",
        "# ... (rest of the code for generate_text, process_and_stream remains the same)\n",
        "\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            yield text\n",
        "\n",
        "# Async function to process text-to-speech and stream through WebSocket\n",
        "async def process_and_stream(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Stream the generated speech through a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "            # Play audio in real-time\n",
        "            play_audio(audio_chunk)  # Play the audio chunk locally\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "# Function to save audio to a file\n",
        "def save_audio_to_file(audio_data, filename=\"output.wav\"):\n",
        "    \"\"\"Saves audio data to a WAV file.\"\"\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(audio_data)\n",
        "    print(f\"Audio saved to {filename}\")\n",
        "\n",
        "# Async function to process text-to-speech and save to file\n",
        "async def process_and_save(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Collect all audio chunks into a BytesIO object\n",
        "    audio_buffer = io.BytesIO()\n",
        "    async for audio_chunk in processor.process(llm_output):\n",
        "        audio_buffer.write(audio_chunk)\n",
        "\n",
        "    # Save the collected audio data to a file\n",
        "    audio_data = audio_buffer.getvalue()\n",
        "    save_audio_to_file(audio_data)\n",
        "\n",
        "# Main function to run the real-time input and streaming\n",
        "async def main():\n",
        "    print(\"Real-Time Text to Speech (Download). Type your query and press Enter. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Call the process_and_save function to handle the user input\n",
        "        await process_and_save(user_input)\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()  # Apply nest_asyncio patch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8pBXpPBzx3L",
        "outputId": "70cf0ee3-cc2e-4f4e-b271-3057a281c02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real-Time Text to Speech (Download). Type your query and press Enter. Type 'exit' to quit.\n",
            "You: hi i am nadeem who are  you is there everything fine ? \n",
            "Audio saved to output.wav\n",
            "You: hi i am nadeem who are  you is there everything fine ?\n",
            "Audio saved to output.wav\n",
            "You: exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio  # Import nest_asyncio\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import io\n",
        "import wave  # Import wave for WAV file manipulation\n",
        "import scipy.io.wavfile as wavfile # Import for saving WAV files\n",
        "\n",
        "# Get API keys from Colab's userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key = userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\"  # Mock WebSocket server\n",
        "\n",
        "# Audio Configuration\n",
        "SAMPLE_RATE = 24000  # 16 kHz for better TTS quality\n",
        "\n",
        "# ... (rest of your code for generate_text, process_and_stream remains the same) ...\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            yield text\n",
        "# Async function to process text-to-speech and stream through WebSocket\n",
        "async def process_and_stream(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Stream the generated speech through a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "            # Play audio in real-time\n",
        "            play_audio(audio_chunk)  # Play the audio chunk locally\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "\n",
        "# Function to save audio to a file\n",
        "def save_audio_to_file(audio_data, filename=\"output.wav\"):\n",
        "    \"\"\"Saves audio data to a WAV file.\"\"\"\n",
        "    # Convert the audio data to a NumPy array\n",
        "    audio_array = np.frombuffer(audio_data, dtype=np.int16)\n",
        "    # Save the audio array as a WAV file\n",
        "    wavfile.write(filename, SAMPLE_RATE, audio_array)\n",
        "    print(f\"Audio saved to {filename}\")\n",
        "\n",
        "\n",
        "# Async function to process text-to-speech and save to file\n",
        "async def process_and_save(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Collect all audio chunks into a BytesIO object\n",
        "    audio_buffer = io.BytesIO()\n",
        "    async for audio_chunk in processor.process(llm_output):\n",
        "        audio_buffer.write(audio_chunk)\n",
        "\n",
        "    # Save the collected audio data to a file\n",
        "    audio_data = audio_buffer.getvalue()\n",
        "    save_audio_to_file(audio_data)\n",
        "\n",
        "# Main function to run the real-time input and streaming\n",
        "async def main():\n",
        "    print(\"Real-Time Text to Speech (Download). Type your query and press Enter. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Call the process_and_save function to handle the user input\n",
        "        await process_and_save(user_input)\n",
        "\n",
        "# ... (rest of your code remains the same) ...\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()  # Apply nest_asyncio patch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0J4XZqi00Lm",
        "outputId": "18fd9422-13e3-409e-c5a7-39e66ebd37f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real-Time Text to Speech (Download). Type your query and press Enter. Type 'exit' to quit.\n",
            "You: hi i am nadeem who are  you is there everything fine ?\n",
            "Audio saved to output.wav\n",
            "You: hi i am nadeem who are  you is there everything fine ?\n",
            "Audio saved to output.wav\n",
            "You: exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio  # Import nest_asyncio\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import io\n",
        "import wave  # Import wave for WAV file manipulation\n",
        "import scipy.io.wavfile as wavfile  # Import for saving WAV files\n",
        "\n",
        "# Get API keys from Colab's userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key = userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "# Initialize Groq (LLM) and Smallest (TTS) instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\"  # Mock WebSocket server\n",
        "\n",
        "# Audio Configuration\n",
        "SAMPLE_RATE = 24000  # 24 kHz for better TTS quality\n",
        "\n",
        "# Async function to stream text generation from LLM\n",
        "async def generate_text(prompt):\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            print(\"LLM Output:\", text)  # Display each chunk of text\n",
        "            yield text\n",
        "\n",
        "# Async function to process text-to-speech and stream through WebSocket\n",
        "async def process_and_stream(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Stream the generated speech through a websocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive the echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "# Function to save audio to a file\n",
        "def save_audio_to_file(audio_data, filename=\"output.wav\"):\n",
        "    \"\"\"Saves audio data to a WAV file.\"\"\"\n",
        "    # Convert the audio data to a NumPy array\n",
        "    audio_array = np.frombuffer(audio_data, dtype=np.int16)\n",
        "    # Save the audio array as a WAV file\n",
        "    wavfile.write(filename, SAMPLE_RATE, audio_array)\n",
        "    print(f\"Audio saved to {filename}\")\n",
        "\n",
        "# Async function to process text-to-speech and save to file\n",
        "async def process_and_save(prompt):\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Collect all audio chunks into a BytesIO object\n",
        "    audio_buffer = io.BytesIO()\n",
        "    async for audio_chunk in processor.process(llm_output):\n",
        "        audio_buffer.write(audio_chunk)\n",
        "\n",
        "    # Save the collected audio data to a file\n",
        "    audio_data = audio_buffer.getvalue()\n",
        "    save_audio_to_file(audio_data)\n",
        "\n",
        "# Main function to run the real-time input and streaming\n",
        "async def main():\n",
        "    print(\"Real-Time Text to Speech (LLM Output Display). Type your query and press Enter. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Call the process_and_save function to handle the user input\n",
        "        await process_and_save(user_input)\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()  # Apply nest_asyncio patch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JdUiSEI1-KJ",
        "outputId": "5f3daa8f-5b86-40fe-dfeb-87eb92afcb9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real-Time Text to Speech (LLM Output Display). Type your query and press Enter. Type 'exit' to quit.\n",
            "You: hi i am nadeem who are  you is there everything fine ?\n",
            "LLM Output: Hello\n",
            "LLM Output:  N\n",
            "LLM Output: ade\n",
            "LLM Output: em\n",
            "LLM Output: !\n",
            "LLM Output:  I\n",
            "LLM Output: 'm\n",
            "LLM Output:  the\n",
            "LLM Output:  AI\n",
            "LLM Output:  assistant\n",
            "LLM Output: ,\n",
            "LLM Output:  nice\n",
            "LLM Output:  to\n",
            "LLM Output:  meet\n",
            "LLM Output:  you\n",
            "LLM Output: !\n",
            "LLM Output:  I\n",
            "LLM Output: 'm\n",
            "LLM Output:  here\n",
            "LLM Output:  to\n",
            "LLM Output:  help\n",
            "LLM Output:  answer\n",
            "LLM Output:  any\n",
            "LLM Output:  questions\n",
            "LLM Output:  you\n",
            "LLM Output:  may\n",
            "LLM Output:  have\n",
            "LLM Output: ,\n",
            "LLM Output:  or\n",
            "LLM Output:  just\n",
            "LLM Output:  chat\n",
            "LLM Output:  about\n",
            "LLM Output:  anything\n",
            "LLM Output:  that\n",
            "LLM Output: 's\n",
            "LLM Output:  on\n",
            "LLM Output:  your\n",
            "LLM Output:  mind\n",
            "LLM Output: .\n",
            "LLM Output:  As\n",
            "LLM Output:  for\n",
            "LLM Output:  me\n",
            "LLM Output: ,\n",
            "LLM Output:  I\n",
            "LLM Output: 'm\n",
            "LLM Output:  just\n",
            "LLM Output:  a\n",
            "LLM Output:  computer\n",
            "LLM Output:  program\n",
            "LLM Output: ,\n",
            "LLM Output:  so\n",
            "LLM Output:  I\n",
            "LLM Output:  don\n",
            "LLM Output: 't\n",
            "LLM Output:  have\n",
            "LLM Output:  feelings\n",
            "LLM Output:  or\n",
            "LLM Output:  emotions\n",
            "LLM Output:  like\n",
            "LLM Output:  humans\n",
            "LLM Output:  do\n",
            "LLM Output: ,\n",
            "LLM Output:  but\n",
            "LLM Output:  I\n",
            "LLM Output: 'm\n",
            "LLM Output:  functioning\n",
            "LLM Output:  properly\n",
            "LLM Output:  and\n",
            "LLM Output:  ready\n",
            "LLM Output:  to\n",
            "LLM Output:  help\n",
            "LLM Output:  you\n",
            "LLM Output:  with\n",
            "LLM Output:  whatever\n",
            "LLM Output:  you\n",
            "LLM Output:  need\n",
            "LLM Output: !\n",
            "Audio saved to output.wav\n",
            "You: exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete flow"
      ],
      "metadata": {
        "id": "hbw8un9X6qNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Imports\n",
        "import assemblyai as aai\n",
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import scipy.io.wavfile as wavfile\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops in Jupyter or Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Get API keys from Colab's userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "Smallest_AI_API_Key = userdata.get('Smallest_AI_API_Key')\n",
        "\n",
        "\n",
        "# API Keys\n",
        "aai.settings.api_key = \"78884175e5a3456a9394a33ebf3871a4\"\n",
        "\n",
        "\n",
        "# WebSocket Server URL\n",
        "WEBSOCKET_URL = \"wss://echo.websocket.events\"  # Mock WebSocket server for testing\n",
        "\n",
        "# Audio Configuration\n",
        "SAMPLE_RATE = 24000  # 24 kHz for better TTS quality\n",
        "\n",
        "# Initialize LLM and TTS instances\n",
        "llm = Groq(api_key=GROQ_API_KEY)\n",
        "tts = Smallest(api_key=Smallest_AI_API_Key)\n",
        "\n",
        "# Function to Transcribe Voice Input\n",
        "def transcribe_audio(file_url):\n",
        "    \"\"\"Transcribe audio using AssemblyAI.\"\"\"\n",
        "    transcriber = aai.Transcriber()\n",
        "    transcript = transcriber.transcribe(file_url)\n",
        "\n",
        "    if transcript.status == aai.TranscriptStatus.error:\n",
        "        print(\"Transcription Error:\", transcript.error)\n",
        "        return None\n",
        "    else:\n",
        "        print(\"Transcription:\", transcript.text)\n",
        "        return transcript.text\n",
        "\n",
        "# Async Function to Generate Text from LLM\n",
        "async def generate_text(prompt):\n",
        "    \"\"\"Generate text from LLM using Groq.\"\"\"\n",
        "    completion = llm.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        stream=True,\n",
        "    )\n",
        "    # Yield text as it is generated\n",
        "    for chunk in completion:\n",
        "        text = chunk.choices[0].delta.content\n",
        "        if text:\n",
        "            print(\"LLM Output:\", text)\n",
        "            yield text\n",
        "\n",
        "# Async Function to Stream TTS Output through WebSocket\n",
        "async def process_and_stream(prompt):\n",
        "    \"\"\"Stream TTS output using Smallest and WebSocket.\"\"\"\n",
        "    # Initialize TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Stream the generated speech through WebSocket\n",
        "    async with websockets.connect(WEBSOCKET_URL) as ws:\n",
        "        print(\"Connected to WebSocket server.\")\n",
        "\n",
        "        # Stream the generated speech\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            await ws.send(audio_chunk)  # Send audio chunk\n",
        "            echoed_data = await ws.recv()  # Receive echoed message\n",
        "            print(\"Received from server:\", echoed_data[:20], \"...\")  # Print first 20 bytes\n",
        "\n",
        "        print(\"WebSocket connection closed.\")\n",
        "\n",
        "# Function to Save Audio to File\n",
        "def save_audio_to_file(audio_data, filename=\"output.wav\"):\n",
        "    \"\"\"Saves audio data to a WAV file.\"\"\"\n",
        "    # Convert the audio data to a NumPy array\n",
        "    audio_array = np.frombuffer(audio_data, dtype=np.int16)\n",
        "    # Save the audio array as a WAV file\n",
        "    wavfile.write(filename, SAMPLE_RATE, audio_array)\n",
        "    print(f\"Audio saved to {filename}\")\n",
        "\n",
        "# Async Function to Process Text-to-Speech and Save to File\n",
        "async def process_and_save(prompt):\n",
        "    \"\"\"Process LLM output and save TTS output to file.\"\"\"\n",
        "    # Initialize the TTS processor\n",
        "    processor = TextToAudioStream(tts_instance=tts)\n",
        "\n",
        "    # Generate text from LLM\n",
        "    llm_output = generate_text(prompt)\n",
        "\n",
        "    # Collect all audio chunks into a BytesIO object\n",
        "    audio_buffer = io.BytesIO()\n",
        "    async for audio_chunk in processor.process(llm_output):\n",
        "        audio_buffer.write(audio_chunk)\n",
        "\n",
        "    # Save the collected audio data to a file\n",
        "    audio_data = audio_buffer.getvalue()\n",
        "    save_audio_to_file(audio_data)\n",
        "\n",
        "# Main Function to Run the Real-Time Input and Streaming\n",
        "async def main():\n",
        "    print(\"Voice-to-Text to LLM to TTS Flow\")\n",
        "\n",
        "    # Step 1: Voice Input (Provide the file path of the recorded audio)\n",
        "    FILE_URL = \"/content/drive/MyDrive/Testing_Voice_to_Speech-VOices/Recording.m4a\"\n",
        "\n",
        "    # Step 2: Transcribe Audio\n",
        "    transcribed_text = transcribe_audio(FILE_URL)\n",
        "    if not transcribed_text:\n",
        "        print(\"Failed to transcribe audio.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Process Transcribed Text and Generate TTS\n",
        "    await process_and_save(transcribed_text)\n",
        "\n",
        "# Run the Main Function\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF_UWg_w6pge",
        "outputId": "a5fa5500-6785-454e-80cf-f6660edcc6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voice-to-Text to LLM to TTS Flow\n",
            "Transcription: Hello there. My name is Basim and I'm currently working in Metavest Pro as an AI ML engineer. Currently I'm working on two projects. The first one is the pan in which the client's name is Osama. He's very naughty boy. The second one is Mithra. The client is very nasty and very, very. You know, there's no words to explain that client. He says that I doesn't know how to implement the AI and he's his self using the platform and that's all. That's it.\n",
            "LLM Output: Hello\n",
            "LLM Output:  Bas\n",
            "LLM Output: im\n",
            "LLM Output: !\n",
            "LLM Output:  It\n",
            "LLM Output: 's\n",
            "LLM Output:  great\n",
            "LLM Output:  to\n",
            "LLM Output:  meet\n",
            "LLM Output:  you\n",
            "LLM Output:  and\n",
            "LLM Output:  hear\n",
            "LLM Output:  about\n",
            "LLM Output:  your\n",
            "LLM Output:  work\n",
            "LLM Output:  as\n",
            "LLM Output:  an\n",
            "LLM Output:  AI\n",
            "LLM Output:  ML\n",
            "LLM Output:  engineer\n",
            "LLM Output:  at\n",
            "LLM Output:  Met\n",
            "LLM Output: av\n",
            "LLM Output: est\n",
            "LLM Output:  Pro\n",
            "LLM Output: .\n",
            "LLM Output:  It\n",
            "LLM Output:  sounds\n",
            "LLM Output:  like\n",
            "LLM Output:  you\n",
            "LLM Output: 're\n",
            "LLM Output:  working\n",
            "LLM Output:  on\n",
            "LLM Output:  two\n",
            "LLM Output:  projects\n",
            "LLM Output: ,\n",
            "LLM Output:  Pan\n",
            "LLM Output:  and\n",
            "LLM Output:  M\n",
            "LLM Output: ith\n",
            "LLM Output: ra\n",
            "LLM Output: ,\n",
            "LLM Output:  for\n",
            "LLM Output:  clients\n",
            "LLM Output:  Osama\n",
            "LLM Output:  and\n",
            "LLM Output:  the\n",
            "LLM Output:  other\n",
            "LLM Output:  client\n",
            "LLM Output: ,\n",
            "LLM Output:  respectively\n",
            "LLM Output: .\n",
            "\n",
            "\n",
            "LLM Output: I\n",
            "LLM Output: 'm\n",
            "LLM Output:  here\n",
            "LLM Output:  to\n",
            "LLM Output:  listen\n",
            "LLM Output:  and\n",
            "LLM Output:  offer\n",
            "LLM Output:  any\n",
            "LLM Output:  help\n",
            "LLM Output:  or\n",
            "LLM Output:  support\n",
            "LLM Output:  I\n",
            "LLM Output:  can\n",
            "LLM Output: .\n",
            "LLM Output:  It\n",
            "LLM Output:  can\n",
            "LLM Output:  be\n",
            "LLM Output:  challenging\n",
            "LLM Output:  to\n",
            "LLM Output:  work\n",
            "LLM Output:  with\n",
            "LLM Output:  clients\n",
            "LLM Output:  who\n",
            "LLM Output:  may\n",
            "LLM Output:  not\n",
            "LLM Output:  be\n",
            "LLM Output:  particularly\n",
            "LLM Output:  friendly\n",
            "LLM Output:  or\n",
            "LLM Output:  understanding\n",
            "LLM Output: ,\n",
            "LLM Output:  but\n",
            "LLM Output:  it\n",
            "LLM Output: 's\n",
            "LLM Output:  great\n",
            "LLM Output:  that\n",
            "LLM Output:  you\n",
            "LLM Output: 're\n",
            "LLM Output:  taking\n",
            "LLM Output:  on\n",
            "LLM Output:  the\n",
            "LLM Output:  challenge\n",
            "LLM Output: .\n",
            "\n",
            "\n",
            "LLM Output: Can\n",
            "LLM Output:  you\n",
            "LLM Output:  tell\n",
            "LLM Output:  me\n",
            "LLM Output:  a\n",
            "LLM Output:  bit\n",
            "LLM Output:  more\n",
            "LLM Output:  about\n",
            "LLM Output:  the\n",
            "LLM Output:  projects\n",
            "LLM Output:  themselves\n",
            "LLM Output: ?\n",
            "LLM Output:  What\n",
            "LLM Output:  are\n",
            "LLM Output:  they\n",
            "LLM Output:  trying\n",
            "LLM Output:  to\n",
            "LLM Output:  achieve\n",
            "LLM Output: ,\n",
            "LLM Output:  and\n",
            "LLM Output:  what\n",
            "LLM Output:  kind\n",
            "LLM Output:  of\n",
            "LLM Output:  AI\n",
            "LLM Output:  and\n",
            "LLM Output:  ML\n",
            "LLM Output:  techniques\n",
            "LLM Output:  are\n",
            "LLM Output:  you\n",
            "LLM Output:  using\n",
            "LLM Output: ?\n",
            "LLM Output:  Additionally\n",
            "LLM Output: ,\n",
            "LLM Output:  have\n",
            "LLM Output:  you\n",
            "LLM Output:  talked\n",
            "LLM Output:  to\n",
            "LLM Output:  your\n",
            "LLM Output:  clients\n",
            "LLM Output:  about\n",
            "LLM Output:  any\n",
            "LLM Output:  issues\n",
            "LLM Output:  or\n",
            "LLM Output:  concerns\n",
            "LLM Output:  they\n",
            "LLM Output:  may\n",
            "LLM Output:  have\n",
            "LLM Output: ,\n",
            "LLM Output:  or\n",
            "LLM Output:  is\n",
            "LLM Output:  there\n",
            "LLM Output:  anything\n",
            "LLM Output:  in\n",
            "LLM Output:  particular\n",
            "LLM Output:  that\n",
            "LLM Output: 's\n",
            "LLM Output:  causing\n",
            "LLM Output:  tension\n",
            "LLM Output:  or\n",
            "LLM Output:  frustration\n",
            "LLM Output:  in\n",
            "LLM Output:  the\n",
            "LLM Output:  projects\n",
            "LLM Output: ?\n",
            "Audio saved to output.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import assemblyai as aai\n",
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import scipy.io.wavfile as wavfile\n",
        "from typing import List, Dict\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops in Jupyter or Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "class ConversationMemory:\n",
        "    def __init__(self, max_history: int = 10):\n",
        "        self.conversations: List[Dict] = []\n",
        "        self.max_history = max_history\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        \"\"\"Add a message to the conversation history.\"\"\"\n",
        "        timestamp = datetime.now().isoformat()\n",
        "        self.conversations.append({\n",
        "            \"role\": role,\n",
        "            \"content\": content,\n",
        "            \"timestamp\": timestamp\n",
        "        })\n",
        "\n",
        "        # Maintain max history limit\n",
        "        if len(self.conversations) > self.max_history:\n",
        "            self.conversations = self.conversations[-self.max_history:]\n",
        "\n",
        "    def get_conversation_history(self) -> List[Dict]:\n",
        "        \"\"\"Return the conversation history.\"\"\"\n",
        "        return self.conversations\n",
        "\n",
        "    def clear_history(self):\n",
        "        \"\"\"Clear the conversation history.\"\"\"\n",
        "        self.conversations = []\n",
        "\n",
        "    def save_to_file(self, filename: str = \"conversation_history.json\"):\n",
        "        \"\"\"Save conversation history to a JSON file.\"\"\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.conversations, f, indent=2)\n",
        "\n",
        "    def load_from_file(self, filename: str = \"conversation_history.json\"):\n",
        "        \"\"\"Load conversation history from a JSON file.\"\"\"\n",
        "        try:\n",
        "            with open(filename, 'r') as f:\n",
        "                self.conversations = json.load(f)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"No history file found at {filename}\")\n",
        "\n",
        "class VoiceChatSystem:\n",
        "    def __init__(self, groq_api_key: str, smallest_api_key: str, assembly_api_key: str):\n",
        "        # Initialize API keys\n",
        "        self.groq_api_key = groq_api_key\n",
        "        self.smallest_api_key = smallest_api_key\n",
        "        aai.settings.api_key = assembly_api_key\n",
        "\n",
        "        # Initialize components\n",
        "        self.llm = Groq(api_key=self.groq_api_key)\n",
        "        self.tts = Smallest(api_key=self.smallest_api_key)\n",
        "        self.memory = ConversationMemory()\n",
        "\n",
        "        # Audio configuration\n",
        "        self.sample_rate = 24000\n",
        "\n",
        "        # System prompt for the LLM\n",
        "        self.system_prompt = \"\"\"\n",
        "        You are an AI assistant engaging in voice conversation. Your responses should be:\n",
        "        1. Natural and conversational in tone\n",
        "        2. Concise yet informative\n",
        "        3. Appropriate for spoken dialogue\n",
        "\n",
        "        Remember to:\n",
        "        - Maintain context from previous messages\n",
        "        - Ask for clarification when needed\n",
        "        - Use appropriate verbal transitions\n",
        "        - Keep responses focused and relevant\n",
        "\n",
        "        Previous conversation context will be provided if available.\n",
        "        \"\"\"\n",
        "\n",
        "    def transcribe_audio(self, file_url: str) -> str:\n",
        "        \"\"\"Transcribe audio using AssemblyAI.\"\"\"\n",
        "        transcriber = aai.Transcriber()\n",
        "        transcript = transcriber.transcribe(file_url)\n",
        "\n",
        "        if transcript.status == aai.TranscriptStatus.error:\n",
        "            print(\"Transcription Error:\", transcript.error)\n",
        "            return None\n",
        "\n",
        "        print(\"Transcription:\", transcript.text)\n",
        "        self.memory.add_message(\"user\", transcript.text)\n",
        "        return transcript.text\n",
        "\n",
        "    async def generate_text(self, prompt: str):\n",
        "        \"\"\"Generate text from LLM using Groq with conversation history.\"\"\"\n",
        "        # Prepare messages with system prompt and history\n",
        "        messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
        "\n",
        "        # Add conversation history\n",
        "        for msg in self.memory.get_conversation_history():\n",
        "            messages.append({\n",
        "                \"role\": msg[\"role\"],\n",
        "                \"content\": msg[\"content\"]\n",
        "            })\n",
        "\n",
        "        # Add current prompt\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        # Generate response\n",
        "        completion = self.llm.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=\"llama3-8b-8192\",\n",
        "            stream=True,\n",
        "        )\n",
        "\n",
        "        # Collect and yield response\n",
        "        response_text = \"\"\n",
        "        for chunk in completion:\n",
        "            text = chunk.choices[0].delta.content\n",
        "            if text:\n",
        "                print(\"LLM Output:\", text)\n",
        "                response_text += text\n",
        "                yield text\n",
        "\n",
        "        # Save assistant's response to memory\n",
        "        self.memory.add_message(\"assistant\", response_text)\n",
        "\n",
        "    async def process_and_stream(self, prompt: str):\n",
        "        \"\"\"Stream TTS output using Smallest and WebSocket.\"\"\"\n",
        "        processor = TextToAudioStream(tts_instance=self.tts)\n",
        "        llm_output = self.generate_text(prompt)\n",
        "\n",
        "        async with websockets.connect(\"wss://echo.websocket.events\") as ws:\n",
        "            print(\"Connected to WebSocket server.\")\n",
        "\n",
        "            async for audio_chunk in processor.process(llm_output):\n",
        "                await ws.send(audio_chunk)\n",
        "                echoed_data = await ws.recv()\n",
        "                print(\"Received from server:\", echoed_data[:20], \"...\")\n",
        "\n",
        "            print(\"WebSocket connection closed.\")\n",
        "\n",
        "    def save_audio_to_file(self, audio_data: bytes, filename: str = \"output.wav\"):\n",
        "        \"\"\"Saves audio data to a WAV file.\"\"\"\n",
        "        audio_array = np.frombuffer(audio_data, dtype=np.int16)\n",
        "        wavfile.write(filename, self.sample_rate, audio_array)\n",
        "        print(f\"Audio saved to {filename}\")\n",
        "\n",
        "    async def process_and_save(self, prompt: str):\n",
        "        \"\"\"Process LLM output and save TTS output to file.\"\"\"\n",
        "        processor = TextToAudioStream(tts_instance=self.tts)\n",
        "        llm_output = self.generate_text(prompt)\n",
        "\n",
        "        audio_buffer = io.BytesIO()\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            audio_buffer.write(audio_chunk)\n",
        "\n",
        "        audio_data = audio_buffer.getvalue()\n",
        "        self.save_audio_to_file(audio_data)\n",
        "\n",
        "async def main():\n",
        "    # Initialize the system with your API keys\n",
        "    system = VoiceChatSystem(\n",
        "        groq_api_key=GROQ_API_KEY,\n",
        "        smallest_api_key=Smallest_AI_API_Key,\n",
        "        assembly_api_key=\"78884175e5a3456a9394a33ebf3871a4\"\n",
        "    )\n",
        "\n",
        "    # Load any existing conversation history\n",
        "    system.memory.load_from_file()\n",
        "\n",
        "    print(\"Voice-to-Text to LLM to TTS Flow\")\n",
        "\n",
        "    # Process voice input\n",
        "    file_url = \"/content/drive/MyDrive/Testing_Voice_to_Speech-VOices/Recording.m4a\"\n",
        "    transcribed_text = system.transcribe_audio(file_url)\n",
        "\n",
        "    if not transcribed_text:\n",
        "        print(\"Failed to transcribe audio.\")\n",
        "        return\n",
        "\n",
        "    # Process and save the response\n",
        "    await system.process_and_save(transcribed_text)\n",
        "\n",
        "    # Save the updated conversation history\n",
        "    system.memory.save_to_file()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUM_lxKB6ozu",
        "outputId": "6c8f09a6-6556-49b3-de41-b2ccf90eca3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No history file found at conversation_history.json\n",
            "Voice-to-Text to LLM to TTS Flow\n",
            "Transcription: Hello, my name is nadeem, and I am an AI engineer at metaves pro.\n",
            "LLM Output: Nice\n",
            "LLM Output:  to\n",
            "LLM Output:  meet\n",
            "LLM Output:  you\n",
            "LLM Output: ,\n",
            "LLM Output:  N\n",
            "LLM Output: ade\n",
            "LLM Output: em\n",
            "LLM Output: !\n",
            "LLM Output:  It\n",
            "LLM Output: 's\n",
            "LLM Output:  great\n",
            "LLM Output:  to\n",
            "LLM Output:  hear\n",
            "LLM Output:  that\n",
            "LLM Output:  you\n",
            "LLM Output: 're\n",
            "LLM Output:  an\n",
            "LLM Output:  AI\n",
            "LLM Output:  engineer\n",
            "LLM Output:  at\n",
            "LLM Output:  Met\n",
            "LLM Output: aves\n",
            "LLM Output:  Pro\n",
            "LLM Output: .\n",
            "LLM Output:  What\n",
            "LLM Output:  kind\n",
            "LLM Output:  of\n",
            "LLM Output:  projects\n",
            "LLM Output:  are\n",
            "LLM Output:  you\n",
            "LLM Output:  working\n",
            "LLM Output:  on\n",
            "LLM Output:  currently\n",
            "LLM Output: ?\n",
            "LLM Output:  Are\n",
            "LLM Output:  there\n",
            "LLM Output:  any\n",
            "LLM Output:  specific\n",
            "LLM Output:  areas\n",
            "LLM Output:  of\n",
            "LLM Output:  AI\n",
            "LLM Output:  that\n",
            "LLM Output:  interest\n",
            "LLM Output:  you\n",
            "LLM Output:  the\n",
            "LLM Output:  most\n",
            "LLM Output: ?\n",
            "Audio saved to output.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import assemblyai as aai\n",
        "import asyncio\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest, TextToAudioStream\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import scipy.io.wavfile as wavfile\n",
        "from typing import List, Dict, Tuple\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops in Jupyter or Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "class TimingStats:\n",
        "    def __init__(self):\n",
        "        self.steps: Dict[str, float] = {}\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def record_step(self, step_name: str, duration: float):\n",
        "        \"\"\"Record the duration of a step.\"\"\"\n",
        "        self.steps[step_name] = duration\n",
        "\n",
        "    def get_total_time(self) -> float:\n",
        "        \"\"\"Get total elapsed time.\"\"\"\n",
        "        return time.time() - self.start_time\n",
        "\n",
        "    def print_stats(self):\n",
        "        \"\"\"Print timing statistics.\"\"\"\n",
        "        print(\"\\n=== Timing Statistics ===\")\n",
        "        for step, duration in self.steps.items():\n",
        "            print(f\"{step}: {duration:.2f} seconds\")\n",
        "        print(f\"Total Time: {self.get_total_time():.2f} seconds\")\n",
        "        print(\"=====================\\n\")\n",
        "\n",
        "class ConversationMemory:\n",
        "    def __init__(self, max_history: int = 10):\n",
        "        self.conversations: List[Dict] = []\n",
        "        self.max_history = max_history\n",
        "        self.timing = TimingStats()\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        \"\"\"Add a message to the conversation history.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        timestamp = datetime.now().isoformat()\n",
        "        self.conversations.append({\n",
        "            \"role\": role,\n",
        "            \"content\": content,\n",
        "            \"timestamp\": timestamp\n",
        "        })\n",
        "\n",
        "        # Maintain max history limit\n",
        "        if len(self.conversations) > self.max_history:\n",
        "            self.conversations = self.conversations[-self.max_history:]\n",
        "\n",
        "        self.timing.record_step(\"Memory Update\", time.time() - start_time)\n",
        "\n",
        "    def get_conversation_history(self) -> List[Dict]:\n",
        "        \"\"\"Return the conversation history.\"\"\"\n",
        "        return self.conversations\n",
        "\n",
        "    def save_to_file(self, filename: str = \"conversation_history.json\"):\n",
        "        \"\"\"Save conversation history to a JSON file.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.conversations, f, indent=2)\n",
        "\n",
        "        self.timing.record_step(\"Save History\", time.time() - start_time)\n",
        "\n",
        "class VoiceChatSystem:\n",
        "    def __init__(self, groq_api_key: str, smallest_api_key: str, assembly_api_key: str):\n",
        "        self.timing = TimingStats()\n",
        "\n",
        "        # Initialize API keys and components\n",
        "        start_time = time.time()\n",
        "        self.groq_api_key = groq_api_key\n",
        "        self.smallest_api_key = smallest_api_key\n",
        "        aai.settings.api_key = assembly_api_key\n",
        "\n",
        "        self.llm = Groq(api_key=self.groq_api_key)\n",
        "        self.tts = Smallest(api_key=self.smallest_api_key)\n",
        "        self.memory = ConversationMemory()\n",
        "\n",
        "        self.timing.record_step(\"Initialization\", time.time() - start_time)\n",
        "\n",
        "        # Audio configuration\n",
        "        self.sample_rate = 24000\n",
        "\n",
        "        # System prompt for the LLM\n",
        "        self.system_prompt = \"\"\"\n",
        "        You are an AI assistant engaging in voice conversation. Your responses should be:\n",
        "        1. Natural and conversational in tone\n",
        "        2. Concise yet informative\n",
        "        3. Appropriate for spoken dialogue\n",
        "\n",
        "        Remember to:\n",
        "        - Maintain context from previous messages\n",
        "        - Ask for clarification when needed\n",
        "        - Use appropriate verbal transitions\n",
        "        - Keep responses focused and relevant\n",
        "\n",
        "        Previous conversation context will be provided if available.\n",
        "        \"\"\"\n",
        "\n",
        "    def transcribe_audio(self, file_url: str) -> Tuple[str, float]:\n",
        "        \"\"\"Transcribe audio using AssemblyAI.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        transcriber = aai.Transcriber()\n",
        "        transcript = transcriber.transcribe(file_url)\n",
        "\n",
        "        if transcript.status == aai.TranscriptStatus.error:\n",
        "            print(\"Transcription Error:\", transcript.error)\n",
        "            return None\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "        self.timing.record_step(\"Transcription\", duration)\n",
        "\n",
        "        print(\"Transcription:\", transcript.text)\n",
        "        self.memory.add_message(\"user\", transcript.text)\n",
        "        return transcript.text\n",
        "\n",
        "    async def generate_text(self, prompt: str):\n",
        "        \"\"\"Generate text from LLM using Groq with conversation history.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Prepare messages with system prompt and history\n",
        "        messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
        "\n",
        "        # Add conversation history\n",
        "        for msg in self.memory.get_conversation_history():\n",
        "            messages.append({\n",
        "                \"role\": msg[\"role\"],\n",
        "                \"content\": msg[\"content\"]\n",
        "            })\n",
        "\n",
        "        # Add current prompt\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        # Generate response\n",
        "        completion = self.llm.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=\"llama3-8b-8192\",\n",
        "            stream=True,\n",
        "        )\n",
        "\n",
        "        # Collect and yield response\n",
        "        response_text = \"\"\n",
        "        for chunk in completion:\n",
        "            text = chunk.choices[0].delta.content\n",
        "            if text:\n",
        "                print(\"LLM Output:\", text)\n",
        "                response_text += text\n",
        "                yield text\n",
        "\n",
        "        # Save assistant's response to memory\n",
        "        self.memory.add_message(\"assistant\", response_text)\n",
        "\n",
        "        self.timing.record_step(\"LLM Generation\", time.time() - start_time)\n",
        "\n",
        "    async def process_and_save(self, prompt: str):\n",
        "        \"\"\"Process LLM output and save TTS output to file.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        processor = TextToAudioStream(tts_instance=self.tts)\n",
        "        llm_output = self.generate_text(prompt)\n",
        "\n",
        "        audio_buffer = io.BytesIO()\n",
        "        async for audio_chunk in processor.process(llm_output):\n",
        "            audio_buffer.write(audio_chunk)\n",
        "\n",
        "        audio_data = audio_buffer.getvalue()\n",
        "        self.save_audio_to_file(audio_data)\n",
        "\n",
        "        self.timing.record_step(\"TTS Processing\", time.time() - start_time)\n",
        "\n",
        "    def save_audio_to_file(self, audio_data: bytes, filename: str = \"output.wav\"):\n",
        "        \"\"\"Saves audio data to a WAV file.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        audio_array = np.frombuffer(audio_data, dtype=np.int16)\n",
        "        wavfile.write(filename, self.sample_rate, audio_array)\n",
        "\n",
        "        self.timing.record_step(\"Audio Save\", time.time() - start_time)\n",
        "        print(f\"Audio saved to {filename}\")\n",
        "\n",
        "async def main():\n",
        "    overall_timing = TimingStats()\n",
        "\n",
        "    # Initialize the system with your API keys\n",
        "    system = VoiceChatSystem(\n",
        "        groq_api_key=GROQ_API_KEY,\n",
        "        smallest_api_key=Smallest_AI_API_Key,\n",
        "        assembly_api_key=\"78884175e5a3456a9394a33ebf3871a4\"\n",
        "    )\n",
        "\n",
        "    # Load any existing conversation history\n",
        "    #system.memory.load_from_file()\n",
        "\n",
        "    print(\"Voice-to-Text to LLM to TTS Flow\")\n",
        "\n",
        "    # Process voice input\n",
        "    file_url = \"/content/drive/MyDrive/Testing_Voice_to_Speech-VOices/Recording.m4a\"\n",
        "    transcribed_text = system.transcribe_audio(file_url)\n",
        "\n",
        "    if not transcribed_text:\n",
        "        print(\"Failed to transcribe audio.\")\n",
        "        return\n",
        "\n",
        "    # Process and save the response\n",
        "    await system.process_and_save(transcribed_text)\n",
        "\n",
        "    # Save the updated conversation history\n",
        "    system.memory.save_to_file()\n",
        "\n",
        "    # Print timing statistics\n",
        "    print(\"\\n=== Step-by-Step Timing ===\")\n",
        "    system.timing.print_stats()\n",
        "    system.memory.timing.print_stats()\n",
        "\n",
        "    print(\"\\n=== Overall Process Timing ===\")\n",
        "    overall_timing.print_stats()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP6P2aXE3xdo",
        "outputId": "2e7c3ff6-ae3f-45b1-a0fd-90a4f677a162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voice-to-Text to LLM to TTS Flow\n",
            "Transcription: Hello, my name is nadeem, and I am an AI engineer at metaves pro.\n",
            "LLM Output: Nice\n",
            "LLM Output:  to\n",
            "LLM Output:  meet\n",
            "LLM Output:  you\n",
            "LLM Output: ,\n",
            "LLM Output:  N\n",
            "LLM Output: ade\n",
            "LLM Output: em\n",
            "LLM Output: !\n",
            "LLM Output:  It\n",
            "LLM Output: 's\n",
            "LLM Output:  great\n",
            "LLM Output:  to\n",
            "LLM Output:  have\n",
            "LLM Output:  a\n",
            "LLM Output:  conversation\n",
            "LLM Output:  with\n",
            "LLM Output:  someone\n",
            "LLM Output:  who\n",
            "LLM Output: 's\n",
            "LLM Output:  working\n",
            "LLM Output:  on\n",
            "LLM Output:  exciting\n",
            "LLM Output:  AI\n",
            "LLM Output:  projects\n",
            "LLM Output:  at\n",
            "LLM Output:  Met\n",
            "LLM Output: averse\n",
            "LLM Output:  Pro\n",
            "LLM Output: .\n",
            "LLM Output:  What\n",
            "LLM Output:  kind\n",
            "LLM Output:  of\n",
            "LLM Output:  AI\n",
            "LLM Output:  projects\n",
            "LLM Output:  are\n",
            "LLM Output:  you\n",
            "LLM Output:  working\n",
            "LLM Output:  on\n",
            "LLM Output: ,\n",
            "LLM Output:  and\n",
            "LLM Output:  what\n",
            "LLM Output:  are\n",
            "LLM Output:  some\n",
            "LLM Output:  of\n",
            "LLM Output:  the\n",
            "LLM Output:  most\n",
            "LLM Output:  interesting\n",
            "LLM Output:  challenges\n",
            "LLM Output:  you\n",
            "LLM Output: 're\n",
            "LLM Output:  facing\n",
            "LLM Output: ?\n",
            "Audio saved to output.wav\n",
            "\n",
            "=== Step-by-Step Timing ===\n",
            "\n",
            "=== Timing Statistics ===\n",
            "Initialization: 0.07 seconds\n",
            "Transcription: 4.22 seconds\n",
            "LLM Generation: 0.41 seconds\n",
            "Audio Save: 0.00 seconds\n",
            "TTS Processing: 1.50 seconds\n",
            "Total Time: 5.79 seconds\n",
            "=====================\n",
            "\n",
            "\n",
            "=== Timing Statistics ===\n",
            "Memory Update: 0.00 seconds\n",
            "Save History: 0.00 seconds\n",
            "Total Time: 5.72 seconds\n",
            "=====================\n",
            "\n",
            "\n",
            "=== Overall Process Timing ===\n",
            "\n",
            "=== Timing Statistics ===\n",
            "Total Time: 5.79 seconds\n",
            "=====================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Q31ZY9MmbY",
        "outputId": "842e0acc-ff15-41ca-ea2b-e710cc0a0811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                            Version\n",
            "---------------------------------- -------------------\n",
            "absl-py                            1.4.0\n",
            "accelerate                         1.3.0\n",
            "aiofiles                           24.1.0\n",
            "aiohappyeyeballs                   2.4.6\n",
            "aiohttp                            3.11.12\n",
            "aiosignal                          1.3.2\n",
            "alabaster                          1.0.0\n",
            "albucore                           0.0.23\n",
            "albumentations                     2.0.4\n",
            "ale-py                             0.10.1\n",
            "altair                             5.5.0\n",
            "annotated-types                    0.7.0\n",
            "anyio                              3.7.1\n",
            "argon2-cffi                        23.1.0\n",
            "argon2-cffi-bindings               21.2.0\n",
            "array_record                       0.6.0\n",
            "arviz                              0.20.0\n",
            "assemblyai                         0.37.0\n",
            "astropy                            7.0.1\n",
            "astropy-iers-data                  0.2025.2.10.0.33.26\n",
            "astunparse                         1.6.3\n",
            "asyncio                            3.4.3\n",
            "atpublic                           4.1.0\n",
            "attrs                              25.1.0\n",
            "audioread                          3.0.1\n",
            "autograd                           1.7.0\n",
            "babel                              2.17.0\n",
            "backcall                           0.2.0\n",
            "beautifulsoup4                     4.13.3\n",
            "betterproto                        2.0.0b6\n",
            "bigframes                          1.36.0\n",
            "bigquery-magics                    0.5.0\n",
            "bleach                             6.2.0\n",
            "blinker                            1.9.0\n",
            "blis                               0.7.11\n",
            "blosc2                             3.1.0\n",
            "bokeh                              3.6.3\n",
            "Bottleneck                         1.4.2\n",
            "bqplot                             0.12.44\n",
            "branca                             0.8.1\n",
            "CacheControl                       0.14.2\n",
            "cachetools                         5.5.1\n",
            "catalogue                          2.0.10\n",
            "certifi                            2025.1.31\n",
            "cffi                               1.17.1\n",
            "chardet                            5.2.0\n",
            "charset-normalizer                 3.4.1\n",
            "chex                               0.1.88\n",
            "clarabel                           0.10.0\n",
            "click                              8.1.8\n",
            "cloudpathlib                       0.20.0\n",
            "cloudpickle                        3.1.1\n",
            "cmake                              3.31.4\n",
            "cmdstanpy                          1.2.5\n",
            "colorcet                           3.1.0\n",
            "colorlover                         0.3.0\n",
            "colour                             0.1.5\n",
            "community                          1.0.0b1\n",
            "confection                         0.1.5\n",
            "cons                               0.4.6\n",
            "contourpy                          1.3.1\n",
            "cramjam                            2.9.1\n",
            "cryptography                       43.0.3\n",
            "cuda-python                        12.6.0\n",
            "cudf-cu12                          24.12.0\n",
            "cufflinks                          0.17.3\n",
            "cupy-cuda12x                       13.3.0\n",
            "cvxopt                             1.3.2\n",
            "cvxpy                              1.6.0\n",
            "cycler                             0.12.1\n",
            "cyipopt                            1.5.0\n",
            "cymem                              2.0.11\n",
            "Cython                             3.0.12\n",
            "dask                               2024.10.0\n",
            "datascience                        0.17.6\n",
            "db-dtypes                          1.4.1\n",
            "dbus-python                        1.2.18\n",
            "debugpy                            1.8.0\n",
            "decorator                          4.4.2\n",
            "defusedxml                         0.7.1\n",
            "Deprecated                         1.2.18\n",
            "diffusers                          0.32.2\n",
            "distro                             1.9.0\n",
            "dlib                               19.24.2\n",
            "dm-tree                            0.1.9\n",
            "dnspython                          2.7.0\n",
            "docker-pycreds                     0.4.0\n",
            "docstring_parser                   0.16\n",
            "docutils                           0.21.2\n",
            "dopamine_rl                        4.1.2\n",
            "duckdb                             1.1.3\n",
            "earthengine-api                    1.5.2\n",
            "easydict                           1.13\n",
            "editdistance                       0.8.1\n",
            "eerepr                             0.1.0\n",
            "einops                             0.8.1\n",
            "email_validator                    2.2.0\n",
            "en-core-web-sm                     3.7.1\n",
            "entrypoints                        0.4\n",
            "et_xmlfile                         2.0.0\n",
            "etils                              1.12.0\n",
            "etuples                            0.3.9\n",
            "Farama-Notifications               0.0.4\n",
            "fastai                             2.7.18\n",
            "fastcore                           1.7.29\n",
            "fastdownload                       0.0.7\n",
            "fastjsonschema                     2.21.1\n",
            "fastprogress                       1.0.3\n",
            "fastrlock                          0.8.3\n",
            "filelock                           3.17.0\n",
            "filetype                           1.2.0\n",
            "firebase-admin                     6.6.0\n",
            "Flask                              3.1.0\n",
            "flatbuffers                        25.2.10\n",
            "flax                               0.10.3\n",
            "folium                             0.19.4\n",
            "fonttools                          4.56.0\n",
            "frozendict                         2.4.6\n",
            "frozenlist                         1.5.0\n",
            "fsspec                             2024.10.0\n",
            "future                             1.0.0\n",
            "gast                               0.6.0\n",
            "gcsfs                              2024.10.0\n",
            "GDAL                               3.6.4\n",
            "gdown                              5.2.0\n",
            "geemap                             0.35.1\n",
            "gensim                             4.3.3\n",
            "geocoder                           1.38.1\n",
            "geographiclib                      2.0\n",
            "geopandas                          1.0.1\n",
            "geopy                              2.4.1\n",
            "gin-config                         0.5.0\n",
            "gitdb                              4.0.12\n",
            "GitPython                          3.1.44\n",
            "glob2                              0.7\n",
            "google                             2.0.3\n",
            "google-ai-generativelanguage       0.6.15\n",
            "google-api-core                    2.19.2\n",
            "google-api-python-client           2.160.0\n",
            "google-auth                        2.27.0\n",
            "google-auth-httplib2               0.2.0\n",
            "google-auth-oauthlib               1.2.1\n",
            "google-cloud-aiplatform            1.79.0\n",
            "google-cloud-bigquery              3.25.0\n",
            "google-cloud-bigquery-connection   1.17.0\n",
            "google-cloud-bigquery-storage      2.28.0\n",
            "google-cloud-bigtable              2.28.1\n",
            "google-cloud-core                  2.4.1\n",
            "google-cloud-dataproc              5.17.0\n",
            "google-cloud-datastore             2.20.2\n",
            "google-cloud-firestore             2.20.0\n",
            "google-cloud-functions             1.19.0\n",
            "google-cloud-iam                   2.18.0\n",
            "google-cloud-language              2.16.0\n",
            "google-cloud-pubsub                2.25.0\n",
            "google-cloud-resource-manager      1.14.0\n",
            "google-cloud-spanner               3.51.0\n",
            "google-cloud-storage               2.19.0\n",
            "google-cloud-translate             3.19.0\n",
            "google-colab                       1.0.0\n",
            "google-crc32c                      1.6.0\n",
            "google-genai                       0.8.0\n",
            "google-generativeai                0.8.4\n",
            "google-pasta                       0.2.0\n",
            "google-resumable-media             2.7.2\n",
            "google-spark-connect               0.5.2\n",
            "googleapis-common-protos           1.67.0\n",
            "googledrivedownloader              1.1.0\n",
            "graphviz                           0.20.3\n",
            "greenlet                           3.1.1\n",
            "groq                               0.18.0\n",
            "grpc-google-iam-v1                 0.14.0\n",
            "grpc-interceptor                   0.15.4\n",
            "grpcio                             1.70.0\n",
            "grpcio-status                      1.62.3\n",
            "grpclib                            0.4.7\n",
            "gspread                            6.1.4\n",
            "gspread-dataframe                  4.0.0\n",
            "gym                                0.25.2\n",
            "gym-notices                        0.0.8\n",
            "gymnasium                          1.0.0\n",
            "h11                                0.14.0\n",
            "h2                                 4.2.0\n",
            "h5netcdf                           1.5.0\n",
            "h5py                               3.12.1\n",
            "highspy                            1.9.0\n",
            "holidays                           0.66\n",
            "holoviews                          1.20.0\n",
            "hpack                              4.1.0\n",
            "html5lib                           1.1\n",
            "httpcore                           1.0.7\n",
            "httpimport                         1.4.0\n",
            "httplib2                           0.22.0\n",
            "httpx                              0.28.1\n",
            "huggingface-hub                    0.28.1\n",
            "humanize                           4.11.0\n",
            "hyperframe                         6.1.0\n",
            "hyperopt                           0.2.7\n",
            "ibis-framework                     9.2.0\n",
            "id                                 1.5.0\n",
            "idna                               3.10\n",
            "imageio                            2.37.0\n",
            "imageio-ffmpeg                     0.6.0\n",
            "imagesize                          1.4.1\n",
            "imbalanced-learn                   0.13.0\n",
            "imgaug                             0.4.0\n",
            "immutabledict                      4.2.1\n",
            "importlib_metadata                 8.6.1\n",
            "importlib_resources                6.5.2\n",
            "imutils                            0.5.4\n",
            "in-toto-attestation                0.9.3\n",
            "inflect                            7.5.0\n",
            "iniconfig                          2.0.0\n",
            "intel-cmplr-lib-ur                 2025.0.4\n",
            "intel-openmp                       2025.0.4\n",
            "ipyevents                          2.0.2\n",
            "ipyfilechooser                     0.6.0\n",
            "ipykernel                          6.17.1\n",
            "ipyleaflet                         0.19.2\n",
            "ipyparallel                        8.8.0\n",
            "ipython                            7.34.0\n",
            "ipython-genutils                   0.2.0\n",
            "ipython-sql                        0.5.0\n",
            "ipytree                            0.2.2\n",
            "ipywidgets                         7.7.1\n",
            "itsdangerous                       2.2.0\n",
            "jax                                0.4.33\n",
            "jax-cuda12-pjrt                    0.4.33\n",
            "jax-cuda12-plugin                  0.4.33\n",
            "jaxlib                             0.4.33\n",
            "jeepney                            0.7.1\n",
            "jellyfish                          1.1.0\n",
            "jieba                              0.42.1\n",
            "Jinja2                             3.1.5\n",
            "jiter                              0.8.2\n",
            "joblib                             1.4.2\n",
            "jsonpatch                          1.33\n",
            "jsonpickle                         4.0.1\n",
            "jsonpointer                        3.0.0\n",
            "jsonschema                         4.23.0\n",
            "jsonschema-specifications          2024.10.1\n",
            "jupyter-client                     6.1.12\n",
            "jupyter-console                    6.1.0\n",
            "jupyter_core                       5.7.2\n",
            "jupyter-leaflet                    0.19.2\n",
            "jupyter-server                     1.24.0\n",
            "jupyterlab_pygments                0.3.0\n",
            "jupyterlab_widgets                 3.0.13\n",
            "kaggle                             1.6.17\n",
            "kagglehub                          0.3.7\n",
            "keras                              3.8.0\n",
            "keras-hub                          0.18.1\n",
            "keras-nlp                          0.18.1\n",
            "keyring                            23.5.0\n",
            "kiwisolver                         1.4.8\n",
            "langchain                          0.3.18\n",
            "langchain-core                     0.3.35\n",
            "langchain-google-genai             2.0.9\n",
            "langchain-text-splitters           0.3.6\n",
            "langcodes                          3.5.0\n",
            "langsmith                          0.3.8\n",
            "language_data                      1.3.0\n",
            "launchpadlib                       1.10.16\n",
            "lazr.restfulclient                 0.14.4\n",
            "lazr.uri                           1.0.6\n",
            "lazy_loader                        0.4\n",
            "libclang                           18.1.1\n",
            "libcudf-cu12                       24.12.0\n",
            "libkvikio-cu12                     24.12.1\n",
            "librosa                            0.10.2.post1\n",
            "lightgbm                           4.5.0\n",
            "linkify-it-py                      2.0.3\n",
            "llvmlite                           0.44.0\n",
            "locket                             1.0.0\n",
            "logical-unification                0.4.6\n",
            "lxml                               5.3.1\n",
            "marisa-trie                        1.2.1\n",
            "Markdown                           3.7\n",
            "markdown-it-py                     3.0.0\n",
            "MarkupSafe                         3.0.2\n",
            "matplotlib                         3.10.0\n",
            "matplotlib-inline                  0.1.7\n",
            "matplotlib-venn                    1.1.1\n",
            "mdit-py-plugins                    0.4.2\n",
            "mdurl                              0.1.2\n",
            "miniKanren                         1.0.3\n",
            "missingno                          0.5.2\n",
            "mistune                            3.1.1\n",
            "mizani                             0.13.1\n",
            "mkl                                2025.0.1\n",
            "ml-dtypes                          0.4.1\n",
            "mlxtend                            0.23.4\n",
            "model-signing                      0.2.0\n",
            "more-itertools                     10.6.0\n",
            "moviepy                            1.0.3\n",
            "mpmath                             1.3.0\n",
            "msgpack                            1.1.0\n",
            "multidict                          6.1.0\n",
            "multipledispatch                   1.0.0\n",
            "multitasking                       0.0.11\n",
            "murmurhash                         1.0.12\n",
            "music21                            9.3.0\n",
            "namex                              0.0.8\n",
            "narwhals                           1.26.0\n",
            "natsort                            8.4.0\n",
            "nbclassic                          1.2.0\n",
            "nbclient                           0.10.2\n",
            "nbconvert                          7.16.6\n",
            "nbformat                           5.10.4\n",
            "ndindex                            1.9.2\n",
            "nest-asyncio                       1.6.0\n",
            "networkx                           3.4.2\n",
            "nibabel                            5.3.2\n",
            "nltk                               3.9.1\n",
            "notebook                           6.5.5\n",
            "notebook_shim                      0.2.4\n",
            "numba                              0.61.0\n",
            "numba-cuda                         0.0.17.1\n",
            "numexpr                            2.10.2\n",
            "numpy                              1.26.4\n",
            "nvidia-cublas-cu12                 12.5.3.2\n",
            "nvidia-cuda-cupti-cu12             12.5.82\n",
            "nvidia-cuda-nvcc-cu12              12.5.82\n",
            "nvidia-cuda-nvrtc-cu12             12.5.82\n",
            "nvidia-cuda-runtime-cu12           12.5.82\n",
            "nvidia-cudnn-cu12                  9.3.0.75\n",
            "nvidia-cufft-cu12                  11.2.3.61\n",
            "nvidia-curand-cu12                 10.3.6.82\n",
            "nvidia-cusolver-cu12               11.6.3.83\n",
            "nvidia-cusparse-cu12               12.5.1.3\n",
            "nvidia-nccl-cu12                   2.21.5\n",
            "nvidia-nvcomp-cu12                 4.1.0.6\n",
            "nvidia-nvjitlink-cu12              12.5.82\n",
            "nvidia-nvtx-cu12                   12.4.127\n",
            "nvtx                               0.2.10\n",
            "nx-cugraph-cu12                    24.12.0\n",
            "oauth2client                       4.1.3\n",
            "oauthlib                           3.2.2\n",
            "openai                             1.61.1\n",
            "opencv-contrib-python              4.11.0.86\n",
            "opencv-python                      4.11.0.86\n",
            "opencv-python-headless             4.11.0.86\n",
            "openpyxl                           3.1.5\n",
            "opentelemetry-api                  1.16.0\n",
            "opentelemetry-sdk                  1.16.0\n",
            "opentelemetry-semantic-conventions 0.37b0\n",
            "opt_einsum                         3.4.0\n",
            "optax                              0.2.4\n",
            "optree                             0.14.0\n",
            "orbax-checkpoint                   0.6.4\n",
            "orjson                             3.10.15\n",
            "osqp                               0.6.7.post3\n",
            "packaging                          24.2\n",
            "pandas                             2.2.2\n",
            "pandas-datareader                  0.10.0\n",
            "pandas-gbq                         0.26.1\n",
            "pandas-stubs                       2.2.2.240909\n",
            "pandocfilters                      1.5.1\n",
            "panel                              1.6.0\n",
            "param                              2.2.0\n",
            "parso                              0.8.4\n",
            "parsy                              2.1\n",
            "partd                              1.4.2\n",
            "pathlib                            1.0.1\n",
            "patsy                              1.0.1\n",
            "peewee                             3.17.9\n",
            "peft                               0.14.0\n",
            "pexpect                            4.9.0\n",
            "pickleshare                        0.7.5\n",
            "pillow                             11.1.0\n",
            "pip                                24.1.2\n",
            "platformdirs                       4.3.6\n",
            "plotly                             5.24.1\n",
            "plotnine                           0.14.5\n",
            "pluggy                             1.5.0\n",
            "ply                                3.11\n",
            "polars                             1.9.0\n",
            "pooch                              1.8.2\n",
            "portpicker                         1.5.2\n",
            "preshed                            3.0.9\n",
            "prettytable                        3.14.0\n",
            "proglog                            0.1.10\n",
            "progressbar2                       4.5.0\n",
            "prometheus_client                  0.21.1\n",
            "promise                            2.3\n",
            "prompt_toolkit                     3.0.50\n",
            "propcache                          0.2.1\n",
            "prophet                            1.1.6\n",
            "proto-plus                         1.26.0\n",
            "protobuf                           4.25.6\n",
            "psutil                             5.9.5\n",
            "psycopg2                           2.9.10\n",
            "ptyprocess                         0.7.0\n",
            "py-cpuinfo                         9.0.0\n",
            "py4j                               0.10.9.7\n",
            "pyarrow                            17.0.0\n",
            "pyasn1                             0.6.1\n",
            "pyasn1_modules                     0.4.1\n",
            "pycocotools                        2.0.8\n",
            "pycparser                          2.22\n",
            "pydantic                           2.10.6\n",
            "pydantic_core                      2.27.2\n",
            "pydata-google-auth                 1.9.1\n",
            "pydot                              3.0.4\n",
            "pydotplus                          2.0.2\n",
            "PyDrive                            1.3.1\n",
            "PyDrive2                           1.21.3\n",
            "pydub                              0.25.1\n",
            "pyerfa                             2.0.1.5\n",
            "pygame                             2.6.1\n",
            "pygit2                             1.17.0\n",
            "Pygments                           2.18.0\n",
            "PyGObject                          3.42.1\n",
            "PyJWT                              2.10.1\n",
            "pylibcudf-cu12                     24.12.0\n",
            "pylibcugraph-cu12                  24.12.0\n",
            "pylibraft-cu12                     24.12.0\n",
            "pymc                               5.20.1\n",
            "pymystem3                          0.2.0\n",
            "pynvjitlink-cu12                   0.5.0\n",
            "pyogrio                            0.10.0\n",
            "Pyomo                              6.8.2\n",
            "PyOpenGL                           3.1.9\n",
            "pyOpenSSL                          24.2.1\n",
            "pyparsing                          3.2.1\n",
            "pyperclip                          1.9.0\n",
            "pyproj                             3.7.0\n",
            "pyshp                              2.3.1\n",
            "PySocks                            1.7.1\n",
            "pyspark                            3.5.4\n",
            "pytensor                           2.27.1\n",
            "pytest                             8.3.4\n",
            "python-apt                         0.0.0\n",
            "python-box                         7.3.2\n",
            "python-dateutil                    2.8.2\n",
            "python-louvain                     0.16\n",
            "python-slugify                     8.0.4\n",
            "python-snappy                      0.7.3\n",
            "python-utils                       3.9.1\n",
            "pytz                               2025.1\n",
            "pyviz_comms                        3.0.4\n",
            "PyYAML                             6.0.2\n",
            "pyzmq                              24.0.1\n",
            "qdldl                              0.1.7.post5\n",
            "ratelim                            0.1.6\n",
            "referencing                        0.36.2\n",
            "regex                              2024.11.6\n",
            "requests                           2.32.3\n",
            "requests-oauthlib                  2.0.0\n",
            "requests-toolbelt                  1.0.0\n",
            "requirements-parser                0.9.0\n",
            "rfc3161-client                     0.1.2\n",
            "rfc8785                            0.1.4\n",
            "rich                               13.9.4\n",
            "rmm-cu12                           24.12.1\n",
            "rpds-py                            0.22.3\n",
            "rpy2                               3.4.2\n",
            "rsa                                4.9\n",
            "sacremoses                         0.1.1\n",
            "safetensors                        0.5.2\n",
            "scikit-image                       0.25.1\n",
            "scikit-learn                       1.6.1\n",
            "scipy                              1.13.1\n",
            "scooby                             0.10.0\n",
            "scs                                3.2.7.post2\n",
            "seaborn                            0.13.2\n",
            "SecretStorage                      3.3.1\n",
            "securesystemslib                   1.2.0\n",
            "Send2Trash                         1.8.3\n",
            "sentence-transformers              3.4.1\n",
            "sentencepiece                      0.2.0\n",
            "sentry-sdk                         2.21.0\n",
            "setproctitle                       1.3.4\n",
            "setuptools                         75.1.0\n",
            "shap                               0.46.0\n",
            "shapely                            2.0.7\n",
            "shellingham                        1.5.4\n",
            "sigstore                           3.6.1\n",
            "sigstore-protobuf-specs            0.3.2\n",
            "sigstore-rekor-types               0.0.18\n",
            "simple-parsing                     0.1.7\n",
            "simsimd                            6.2.1\n",
            "six                                1.17.0\n",
            "sklearn-compat                     0.1.3\n",
            "sklearn-pandas                     2.2.0\n",
            "slicer                             0.0.8\n",
            "smallestai                         2.0.0\n",
            "smart-open                         7.1.0\n",
            "smmap                              5.0.2\n",
            "sniffio                            1.3.1\n",
            "snowballstemmer                    2.2.0\n",
            "sounddevice                        0.5.1\n",
            "soundfile                          0.13.1\n",
            "soupsieve                          2.6\n",
            "soxr                               0.5.0.post1\n",
            "spacy                              3.7.5\n",
            "spacy-legacy                       3.0.12\n",
            "spacy-loggers                      1.0.5\n",
            "spanner-graph-notebook             1.1.1\n",
            "Sphinx                             8.1.3\n",
            "sphinxcontrib-applehelp            2.0.0\n",
            "sphinxcontrib-devhelp              2.0.0\n",
            "sphinxcontrib-htmlhelp             2.1.0\n",
            "sphinxcontrib-jsmath               1.0.1\n",
            "sphinxcontrib-qthelp               2.0.0\n",
            "sphinxcontrib-serializinghtml      2.0.0\n",
            "SQLAlchemy                         2.0.38\n",
            "sqlglot                            25.6.1\n",
            "sqlparse                           0.5.3\n",
            "srsly                              2.5.1\n",
            "stanio                             0.5.1\n",
            "statsmodels                        0.14.4\n",
            "stringzilla                        3.11.3\n",
            "sympy                              1.13.1\n",
            "tables                             3.10.2\n",
            "tabulate                           0.9.0\n",
            "tbb                                2022.0.0\n",
            "tcmlib                             1.2.0\n",
            "tenacity                           9.0.0\n",
            "tensorboard                        2.18.0\n",
            "tensorboard-data-server            0.7.2\n",
            "tensorflow                         2.18.0\n",
            "tensorflow-datasets                4.9.7\n",
            "tensorflow-hub                     0.16.1\n",
            "tensorflow-io-gcs-filesystem       0.37.1\n",
            "tensorflow-metadata                1.16.1\n",
            "tensorflow-probability             0.25.0\n",
            "tensorflow-text                    2.18.1\n",
            "tensorstore                        0.1.71\n",
            "termcolor                          2.5.0\n",
            "terminado                          0.18.1\n",
            "text-unidecode                     1.3\n",
            "textblob                           0.19.0\n",
            "tf_keras                           2.18.0\n",
            "tf-slim                            1.1.0\n",
            "thinc                              8.2.5\n",
            "threadpoolctl                      3.5.0\n",
            "tifffile                           2025.1.10\n",
            "timm                               1.0.14\n",
            "tinycss2                           1.4.0\n",
            "tokenizers                         0.21.0\n",
            "toml                               0.10.2\n",
            "toolz                              0.12.1\n",
            "torch                              2.5.1+cu124\n",
            "torchaudio                         2.5.1+cu124\n",
            "torchsummary                       1.5.1\n",
            "torchvision                        0.20.1+cu124\n",
            "tornado                            6.4.2\n",
            "tqdm                               4.67.1\n",
            "traitlets                          5.7.1\n",
            "traittypes                         0.2.1\n",
            "transformers                       4.48.3\n",
            "treescope                          0.1.8\n",
            "triton                             3.1.0\n",
            "tuf                                5.1.0\n",
            "tweepy                             4.15.0\n",
            "typeguard                          4.4.1\n",
            "typer                              0.15.1\n",
            "types-pytz                         2025.1.0.20250204\n",
            "types-setuptools                   75.8.0.20250210\n",
            "typing_extensions                  4.12.2\n",
            "tzdata                             2025.1\n",
            "tzlocal                            5.3\n",
            "uc-micro-py                        1.0.3\n",
            "umf                                0.9.1\n",
            "uritemplate                        4.1.1\n",
            "urllib3                            2.3.0\n",
            "vega-datasets                      0.9.0\n",
            "wadllib                            1.3.6\n",
            "wandb                              0.19.6\n",
            "wasabi                             1.1.3\n",
            "wcwidth                            0.2.13\n",
            "weasel                             0.4.1\n",
            "webcolors                          24.11.1\n",
            "webencodings                       0.5.1\n",
            "websocket-client                   1.8.0\n",
            "websockets                         14.2\n",
            "Werkzeug                           3.1.3\n",
            "wheel                              0.45.1\n",
            "widgetsnbextension                 3.6.10\n",
            "wordcloud                          1.9.4\n",
            "wrapt                              1.17.2\n",
            "xarray                             2025.1.2\n",
            "xarray-einstats                    0.8.0\n",
            "xgboost                            2.1.4\n",
            "xlrd                               2.0.1\n",
            "xyzservices                        2025.1.0\n",
            "yarl                               1.18.3\n",
            "yellowbrick                        1.5\n",
            "yfinance                           0.2.52\n",
            "zipp                               3.21.0\n",
            "zstandard                          0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "pLgQxN7kNcKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh7djnN3Nm9G",
        "outputId": "c4b0bb4e-529c-4fbf-db84-b5199742bcc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip show assemblyai | grep Version\n",
        "# !pip show websockets | grep Version\n",
        "# !pip show groq | grep Version\n",
        "# !pip show smallest | grep Version\n",
        "# !pip show nest_asyncio | grep Version\n",
        "# !pip show numpy | grep Version\n",
        "!pip show scipy | grep Version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkxd_t6zQ-_R",
        "outputId": "c438e0b6-37ff-4b8c-c350-8f77512fa6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version: 1.13.1\n",
            "Version 3.1, 31 March 2009\n",
            "                       Version 3, 29 June 2007\n",
            "  5. Conveying Modified Source Versions.\n",
            "  14. Revised Versions of this License.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import assemblyai as aai\n",
        "import websockets\n",
        "from groq import Groq\n",
        "from smallest import Smallest\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "print(\"assemblyai:\", aai.__version__)\n",
        "print(\"websockets:\", websockets.__version__)\n",
        "#print(\"groq:\", Groq.__version__)\n",
        "#print(\"smallest:\", Smallest.__version__)\n",
        "print(\"nest_asyncio:\", nest_asyncio.__version__)\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"scipy:\", scipy.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "2jtqIqLjPANC",
        "outputId": "3fbda340-eb35-4db3-fa8a-c3888eff85d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assemblyai: 0.37.0\n",
            "websockets: 14.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'nest_asyncio' has no attribute '__version__'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fe91c888e863>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(\"groq:\", Groq.__version__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#print(\"smallest:\", Smallest.__version__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nest_asyncio:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numpy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scipy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'nest_asyncio' has no attribute '__version__'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sounddevice as sd\n",
        "print(\"sounddevice version:\", sd.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZXiL_EPQr9j",
        "outputId": "1eff22fc-535a-450c-d6af-abc490141ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sounddevice version: 0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show smallest | grep Version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5yaDvp_Sf5y",
        "outputId": "09e4e6b0-7d34-477c-e3f0-2adbbdcae54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: smallest\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tMJDMMx1SnOy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}